{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StanfordDogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepManuPy/convNets/blob/master/StanfordDogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii4J9m-XYAZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Info on how to get your api key (kaggle.json) here: https://github.com/Kaggle/kaggle-api#api-credentials\n",
        "\n",
        "#!pip install -q kaggle\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "api_token = {\"username\":\"reddymanudeep\",\"key\":\"882ba15e574c727d4ef37d746c1d9044\"}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnWjW99-nv4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd /root && ls -a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr9qdSRWUrcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0jKlyOnLJxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KgDAlVFY6Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW_vbX8qZduE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip stanford-dogs-dataset.zip\n",
        "!tar xf images.tar\n",
        "!tar xf annotations.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9zew8O9ojTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "classes = list(os.listdir(\"Images\"))\n",
        "classes.sort()\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V41azXsXzzGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import mkdir\n",
        "mkdir(\"cropped_images\")\n",
        "for name in classes:\n",
        "  os.mkdir(os.path.sep.join([\"cropped_images\",name]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmnXHE3wo-yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from xml.etree import ElementTree\n",
        "\n",
        "for classdir in os.listdir(\"Annotation\"):\n",
        "  subdir = os.path.sep.join([\"Annotation\",classdir])\n",
        "  subimg = os.path.sep.join([\"Images\",classdir])\n",
        "  for filename in os.listdir(subdir):\n",
        "    \n",
        "    tree = ElementTree.parse(os.path.sep.join([subdir,filename]))\n",
        "    root = tree.getroot()\n",
        "    box = root.find(\".//bndbox\")\n",
        "    xmin = int(box.find(\"xmin\").text)\n",
        "    ymin = int(box.find(\"ymin\").text)\n",
        "    xmax = int(box.find(\"xmax\").text)\n",
        "    ymax = int(box.find(\"ymax\").text)\n",
        "    \n",
        "    file = filename+\".jpg\"\n",
        "    img = os.path.sep.join([subimg,file])\n",
        "    image = Image.open(img)\n",
        "    image = image.crop((xmin,ymin,xmax,ymax))\n",
        "    n = img.split(os.path.sep)\n",
        "    file = filename+\".png\"\n",
        "    image.save(os.path.sep.join([\"cropped_images\",classdir,file]))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmL5cEqTLSAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import split_folders\n",
        "\n",
        "split_folders.ratio(\"cropped_images\",output=\"dataset\",seed=1337,ratio=(.8,.1,.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM1BDm29bSx1",
        "colab_type": "code",
        "outputId": "181df80e-e2b5-4bb7-e6c3-546f369bbe30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "train_iter = ImageDataGenerator(rotation_range=30,\n",
        "                               zoom_range=0.15,\n",
        "                               width_shift_range=0.2,\n",
        "                              height_shift_range=0.2,\n",
        "                              shear_range=0.15,\n",
        "                              horizontal_flip=True,\n",
        "                              fill_mode=\"nearest\")\n",
        "\n",
        "#train_iter = ImageDataGenerator()\n",
        "val_iter = ImageDataGenerator()\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "train_iter.mean = mean\n",
        "val_iter.mean = mean\n",
        "\n",
        "train_gen = train_iter.flow_from_directory(\"dataset/train\",\n",
        "                                           class_mode=\"categorical\",\n",
        "                                          target_size = (224,224),\n",
        "                                          shuffle = True,\n",
        "                                          batch_size = 32)\n",
        "val_gen = val_iter.flow_from_directory(\"dataset/val\",\n",
        "                                           class_mode=\"categorical\",\n",
        "                                          target_size = (224,224),\n",
        "                                          shuffle = True,\n",
        "                                          batch_size = 32)\n",
        "\n",
        "test_gen = val_iter.flow_from_directory(\"dataset/test\",\n",
        "                                           class_mode=\"categorical\",\n",
        "                                          target_size = (224,224),\n",
        "                                          shuffle = True,\n",
        "                                          batch_size = 32)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 16418 images belonging to 120 classes.\n",
            "Found 2009 images belonging to 120 classes.\n",
            "Found 2153 images belonging to 120 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZfFURibcrm9",
        "colab_type": "code",
        "outputId": "da0fd506-9df3-4700-d22d-9428b60e46af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Flatten,Dense,Dropout,BatchNormalization,Activation\n",
        "from keras.applications.vgg16 import VGG16,decode_predictions\n",
        "from keras.models import Model\n",
        "\n",
        "base_model = VGG16(include_top=False,input_shape=(224,224,3),weights=\"imagenet\")\n",
        "flat1 = Flatten()(base_model.output)\n",
        "#drop = Dropout(0.4)(flat1)\n",
        "fc = Dense(2048,kernel_initializer=\"he_normal\")(flat1)\n",
        "#drop = Dropout(0.5)(fc)\n",
        "bn = BatchNormalization()(fc)\n",
        "act1 = Activation(\"relu\")(bn)\n",
        "fc1 = Dense(1024,kernel_initializer=\"he_normal\")(act1)\n",
        "#drop1 = Dropout(0.5)(fc1)\n",
        "bn = BatchNormalization()(fc1)\n",
        "act2 = Activation(\"relu\")(bn)\n",
        "out = Dense(120,activation='softmax')(act2)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.inputs,outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2048)              51382272  \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 120)               123000    \n",
            "=================================================================\n",
            "Total params: 68,330,424\n",
            "Trainable params: 68,324,280\n",
            "Non-trainable params: 6,144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAobRXzZvQbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import adam,sgd\n",
        "from keras.callbacks import *\n",
        "\n",
        "ad = adam(lr = 1e-2)\n",
        "for layers in base_model.layers:\n",
        "  layers.trainable = False\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=ad,metrics=['accuracy'])\n",
        "model.load_weights(\"weights_1.489.hdf5\")\n",
        "his = model.fit_generator(train_gen,epochs=5,steps_per_epoch=16670//32,verbose=1,\n",
        "                    validation_data=val_gen,validation_steps=2041//32,callbacks=[\n",
        "                        ModelCheckpoint(\"weights_{val_loss:.3f}.hdf5\",save_best_only=True,\n",
        "                                       save_weights_only=True,verbose=0,mode=\"min\")\n",
        "                    ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxgKqpktUl5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def plot_training(H, N, plotPath):\n",
        "\t# construct a plot that plots and saves the training history\n",
        "\tplt.style.use(\"ggplot\")\n",
        "\tplt.figure()\n",
        "\tplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "\tplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "\tplt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "\tplt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "\tplt.title(\"Training Loss and Accuracy\")\n",
        "\tplt.xlabel(\"Epoch #\")\n",
        "\tplt.ylabel(\"Loss/Accuracy\")\n",
        "\tplt.legend(loc=\"lower left\")\n",
        "\tplt.savefig(plotPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8JV2BkT0W_j0",
        "colab": {}
      },
      "source": [
        "plot_training(his,10,\"WarmUp.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LbunQ2w0rHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "image = load_img(\"dog.jpg\",target_size=(224,224))\n",
        "image = img_to_array(image)\n",
        "image = image/225.0\n",
        "image = image.reshape(1,224,224,3)\n",
        "\n",
        "results = model.predict(image)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbZOA7AZ_CKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen.reset()\n",
        "val_gen.reset()\n",
        "\n",
        "for layer in base_model.layers[15:]:\n",
        "  layers.trainable = True\n",
        "\n",
        "model.load_weights(\"weights.1.38.hdf5\")\n",
        "opt = adam(lr=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "his = model.fit_generator(train_gen,epochs=20,steps_per_epoch=16670//32,verbose=1,\n",
        "                    validation_data=val_gen,validation_steps=2041//32,callbacks=[\n",
        "                        ModelCheckpoint(\"weights-{val_loss:.2f}.hdf5\",save_best_only=True,\n",
        "                                       save_weights_only=True,verbose=0)\n",
        "                    ])\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jOSX9CZLgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}